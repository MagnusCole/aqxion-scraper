# Aqxion Scraper MVP

Un scraper web inteligente para extraer y analizar contenido relacionado con negocios en PerÃº, enfocado en identificar oportunidades de venta y marketing.

## ğŸš€ CaracterÃ­sticas

### ExtracciÃ³n de Datos
- **Scraping stealth**: Usa Scrapling para evitar detecciÃ³n
- **MÃºltiples keywords**: Configurable vÃ­a variables de entorno
- **ExtracciÃ³n de cuerpo**: Obtiene contenido detallado de las pÃ¡ginas
- **DeduplicaciÃ³n inteligente**: Evita contenido duplicado usando slugs

### AnÃ¡lisis de IntenciÃ³n
- **ClasificaciÃ³n automÃ¡tica**: Identifica dolores, bÃºsquedas y objeciones
- **Patrones regex**: Sistema configurable de reglas de negocio
- **Etiquetas semÃ¡nticas**: Categoriza el contenido por intenciÃ³n comercial

### Infraestructura
- **Base de datos SQLite**: Almacenamiento eficiente con WAL mode
- **Logging estructurado**: Seguimiento completo de operaciones
- **ConfiguraciÃ³n externa**: Variables de entorno para fÃ¡cil deployment
- **MÃ©tricas de negocio**: KPIs enfocados en oportunidades de venta

## ğŸ“Š KPIs de Negocio

- **Dolores Ãºnicos**: Problemas identificados en el mercado
- **BÃºsquedas proveedor**: IntenciÃ³n de compra activa
- **Objeciones**: Barreras y preocupaciones del mercado
- **Ruido**: Contenido no relevante (filtrado automÃ¡ticamente)

## ğŸ› ï¸ InstalaciÃ³n

### Prerrequisitos
- Python 3.11+
- Virtual environment

### Setup
```bash
# Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install scrapling selectolax python-dotenv slugify

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus keywords y configuraciÃ³n
```

### ConfiguraciÃ³n (.env)
```env
# Keywords a buscar (separados por pipeline)
KEYWORDS=limpieza de piscina lima|agencia marketing lima|dashboard pymes peru

# MÃ¡ximo de resultados por keyword
MAX_PER_KW=30

# Nivel de logging
LOG_LEVEL=INFO

# API Key para OpenAI (opcional, para futuras mejoras)
OPENAI_API_KEY=your_key_here
```

## ğŸ“ Estructura del Proyecto

```
aqxion-scraper-mvp/
â”œâ”€â”€ main.py              # Script principal de scraping
â”œâ”€â”€ db.py                # Operaciones de base de datos
â”œâ”€â”€ config.py            # ConfiguraciÃ³n y variables de entorno
â”œâ”€â”€ rules.py             # Reglas de clasificaciÃ³n por intenciÃ³n
â”œâ”€â”€ sources.py           # GeneraciÃ³n de URLs de bÃºsqueda
â”œâ”€â”€ kpi.py              # AnÃ¡lisis de mÃ©tricas de negocio
â”œâ”€â”€ viewer.py           # Dashboard de visualizaciÃ³n
â”œâ”€â”€ .env                # Variables de entorno
â””â”€â”€ scraping.db         # Base de datos SQLite
```

## ğŸš€ Uso

### Ejecutar Scraping
```bash
python main.py
```

### Ver Dashboard
```bash
python viewer.py
```

### Ver KPIs
```bash
python kpi.py
```

## ğŸ¯ Reglas de ClasificaciÃ³n

### Dolores (Problemas)
- "necesito", "tengo problema", "no puedo", "difÃ­cil"
- "busco soluciÃ³n", "ayuda con", "cÃ³mo resolver"

### BÃºsquedas (IntenciÃ³n de Compra)
- "busco", "buscando", "quiero contratar"
- "presupuesto", "cotizaciÃ³n", "precio"

### Objeciones (Barreras)
- "caro", "muy caro", "demasiado", "cuesta mucho"
- "no tengo tiempo", "complicado", "difÃ­cil de usar"

## ğŸ“ˆ Resultados de Ejemplo

```
=== KPI DEL DÃA ===
Dolores Ãºnicos: 1
Objeciones: 0
BÃºsquedas proveedor: 1
Ruido: 70
Total Ãºnicos: 102

=== TOP KEYWORDS POR INTENCIÃ“N ===
dashboard pymes peru (dolor): 1
limpieza de piscina lima (busqueda): 1
```

## ğŸ”§ PersonalizaciÃ³n

### Agregar Nuevos Patrones
Edita `rules.py` para agregar nuevos patrones de regex:

```python
patterns = {
    'dolor': [
        re.compile(r'nuevo_patron|otro_patron', re.IGNORECASE),
    ],
    'busqueda': [
        re.compile(r'patron_de_busqueda', re.IGNORECASE),
    ]
}
```

### Modificar Keywords
Actualiza la variable `KEYWORDS` en `.env`:
```env
KEYWORDS=tu keyword|otro keyword|tercer keyword
```

## ğŸ“Š Base de Datos

### Esquema
```sql
CREATE TABLE posts (
    id TEXT PRIMARY KEY,
    keyword TEXT NOT NULL,
    title TEXT NOT NULL,
    url TEXT NOT NULL,
    body TEXT,
    tag TEXT,
    published_at TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_posts_tag ON posts(tag);
CREATE INDEX idx_posts_keyword ON posts(keyword);
```

## ğŸ”„ Mejoras Futuras

- [ ] IntegraciÃ³n con LLM para clasificaciÃ³n mÃ¡s precisa
- [ ] Dashboard web interactivo
- [ ] Scheduler automÃ¡tico
- [ ] Alertas en tiempo real
- [ ] AnÃ¡lisis de sentimientos
- [ ] IntegraciÃ³n con CRM

## ğŸ“ Notas TÃ©cnicas

- **Scrapling**: LibrerÃ­a de scraping que simula navegaciÃ³n real
- **Selectolax**: Parser HTML rÃ¡pido para extracciÃ³n de contenido
- **Slugify**: NormalizaciÃ³n de texto para deduplicaciÃ³n
- **SQLite WAL**: Modo Write-Ahead Logging para mejor performance

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ“ Soporte

Para soporte tÃ©cnico o consultas sobre el proyecto, por favor contacta al equipo de desarrollo.</content>
<filePath">d:\Projects\aqxion-scraper-mvp\README.md</filePath>
<parameter name="content"># Aqxion Scraper MVP

Un scraper web inteligente para extraer y analizar contenido relacionado con negocios en PerÃº, enfocado en identificar oportunidades de venta y marketing.

## ğŸš€ CaracterÃ­sticas

### ExtracciÃ³n de Datos
- **Scraping stealth**: Usa Scrapling para evitar detecciÃ³n
- **MÃºltiples keywords**: Configurable vÃ­a variables de entorno
- **ExtracciÃ³n de cuerpo**: Obtiene contenido detallado de las pÃ¡ginas
- **DeduplicaciÃ³n inteligente**: Evita contenido duplicado usando slugs

### AnÃ¡lisis de IntenciÃ³n
- **ClasificaciÃ³n automÃ¡tica**: Identifica dolores, bÃºsquedas y objeciones
- **Patrones regex**: Sistema configurable de reglas de negocio
- **Etiquetas semÃ¡nticas**: Categoriza el contenido por intenciÃ³n comercial

### Infraestructura
- **Base de datos SQLite**: Almacenamiento eficiente con WAL mode
- **Logging estructurado**: Seguimiento completo de operaciones
- **ConfiguraciÃ³n externa**: Variables de entorno para fÃ¡cil deployment
- **MÃ©tricas de negocio**: KPIs enfocados en oportunidades de venta

## ğŸ“Š KPIs de Negocio

- **Dolores Ãºnicos**: Problemas identificados en el mercado
- **BÃºsquedas proveedor**: IntenciÃ³n de compra activa
- **Objeciones**: Barreras y preocupaciones del mercado
- **Ruido**: Contenido no relevante (filtrado automÃ¡ticamente)

## ğŸ› ï¸ InstalaciÃ³n

### Prerrequisitos
- Python 3.11+
- Virtual environment

### Setup
```bash
# Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install scrapling selectolax python-dotenv slugify

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus keywords y configuraciÃ³n
```

### ConfiguraciÃ³n (.env)
```env
# Keywords a buscar (separados por pipeline)
KEYWORDS=limpieza de piscina lima|agencia marketing lima|dashboard pymes peru

# MÃ¡ximo de resultados por keyword
MAX_PER_KW=30

# Nivel de logging
LOG_LEVEL=INFO

# API Key para OpenAI (opcional, para futuras mejoras)
OPENAI_API_KEY=your_key_here
```

## ğŸ“ Estructura del Proyecto

```
aqxion-scraper-mvp/
â”œâ”€â”€ main.py              # Script principal de scraping
â”œâ”€â”€ db.py                # Operaciones de base de datos
â”œâ”€â”€ config.py            # ConfiguraciÃ³n y variables de entorno
â”œâ”€â”€ rules.py             # Reglas de clasificaciÃ³n por intenciÃ³n
â”œâ”€â”€ sources.py           # GeneraciÃ³n de URLs de bÃºsqueda
â”œâ”€â”€ kpi.py              # AnÃ¡lisis de mÃ©tricas de negocio
â”œâ”€â”€ viewer.py           # Dashboard de visualizaciÃ³n
â”œâ”€â”€ .env                # Variables de entorno
â””â”€â”€ scraping.db         # Base de datos SQLite
```

## ğŸš€ Uso

### Ejecutar Scraping
```bash
python main.py
```

### Ver Dashboard
```bash
python viewer.py
```

### Ver KPIs
```bash
python kpi.py
```

## ğŸ¯ Reglas de ClasificaciÃ³n

### Dolores (Problemas)
- "necesito", "tengo problema", "no puedo", "difÃ­cil"
- "busco soluciÃ³n", "ayuda con", "cÃ³mo resolver"

### BÃºsquedas (IntenciÃ³n de Compra)
- "busco", "buscando", "quiero contratar"
- "presupuesto", "cotizaciÃ³n", "precio"

### Objeciones (Barreras)
- "caro", "muy caro", "demasiado", "cuesta mucho"
- "no tengo tiempo", "complicado", "difÃ­cil de usar"

## ğŸ“ˆ Resultados de Ejemplo

```
=== KPI DEL DÃA ===
Dolores Ãºnicos: 1
Objeciones: 0
BÃºsquedas proveedor: 1
Ruido: 70
Total Ãºnicos: 102

=== TOP KEYWORDS POR INTENCIÃ“N ===
dashboard pymes peru (dolor): 1
limpieza de piscina lima (busqueda): 1
```

## ğŸ”§ PersonalizaciÃ³n

### Agregar Nuevos Patrones
Edita `rules.py` para agregar nuevos patrones de regex:

```python
patterns = {
    'dolor': [
        re.compile(r'nuevo_patron|otro_patron', re.IGNORECASE),
    ],
    'busqueda': [
        re.compile(r'patron_de_busqueda', re.IGNORECASE),
    ]
}
```

### Modificar Keywords
Actualiza la variable `KEYWORDS` en `.env`:
```env
KEYWORDS=tu keyword|otro keyword|tercer keyword
```

## ğŸ“Š Base de Datos

### Esquema
```sql
CREATE TABLE posts (
    id TEXT PRIMARY KEY,
    keyword TEXT NOT NULL,
    title TEXT NOT NULL,
    url TEXT NOT NULL,
    body TEXT,
    tag TEXT,
    published_at TEXT,
    created_at TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_posts_tag ON posts(tag);
CREATE INDEX idx_posts_keyword ON posts(keyword);
```

## ğŸ”„ Mejoras Futuras

- [ ] IntegraciÃ³n con LLM para clasificaciÃ³n mÃ¡s precisa
- [ ] Dashboard web interactivo
- [ ] Scheduler automÃ¡tico
- [ ] Alertas en tiempo real
- [ ] AnÃ¡lisis de sentimientos
- [ ] IntegraciÃ³n con CRM

## ğŸ“ Notas TÃ©cnicas

- **Scrapling**: LibrerÃ­a de scraping que simula navegaciÃ³n real
- **Selectolax**: Parser HTML rÃ¡pido para extracciÃ³n de contenido
- **Slugify**: NormalizaciÃ³n de texto para deduplicaciÃ³n
- **SQLite WAL**: Modo Write-Ahead Logging para mejor performance

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ“ Soporte

Para soporte tÃ©cnico o consultas sobre el proyecto, por favor contacta al equipo de desarrollo.</content>
</xai:function_call">README.md
